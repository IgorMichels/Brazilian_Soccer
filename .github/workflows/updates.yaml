on:
  schedule:
    - cron: "25 7 * * *"

jobs:
  Scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo content
        uses: actions/checkout@v2
      
      - name: Configure repo
        run: |
          git config --global user.name 'IgorMichels'
          git config --global user.email 'igorxadrezbr@gmail.com'
          git pull
      
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      
      - name: Execute scraping
        run: |
          cd Scrape/
          python main.py -s -a
          cd ../
          
      - name: Commit changes (scraping)
        run: |
          git add *
          git commit -m "Automated update"
          git push
      
      - name: Execute script
        run: |
          cd Code/
          cd Commons/
          python script.py
          cd ../
      
      - name: Execute models
        run: |
          cd Bayesian_model/
          python atk_def_model.py
          python home_away_model.py
          python home_away_model_2.py
          cd ../
          cd ../
      
      - name: Commit changes (models)
        run: |
          git add *
          git commit -m "Automated update (parameters sampling)"
          git push

